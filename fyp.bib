
@misc{alammarIllustratedTransformer,
  title = {The {{Illustrated Transformer}}},
  author = {Alammar, Jay},
  abstract = {Discussions: Hacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments) Translations: Chinese (Simplified), French 1, French 2, Japanese, Korean, Russian, Spanish, Vietnamese Watch: MIT's Deep Learning State of the Art lecture referencing this post In the previous post, we looked at Attention \textendash{} a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer \textendash{} a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud's recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let's try to break the model apart and look at how it functions. The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard's NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter. 2020 Update: I've created a ``Narrated Transformer'' video which is a gentler approach to the topic: A High-Level Look Let's begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.},
  howpublished = {https://jalammar.github.io/illustrated-transformer/},
  file = {/home/dimdakis/Zotero/storage/2VK4QG4A/illustrated-transformer.html}
}

@misc{amamouFineTuningLayoutLMV22022,
  title = {Fine-{{Tuning LayoutLM}} v2 {{For Invoice Recognition}}},
  author = {Amamou, Walid},
  year = {2022},
  month = apr,
  journal = {Medium},
  abstract = {From annotation to training and inference},
  howpublished = {https://towardsdatascience.com/fine-tuning-layoutlm-v2-for-invoice-recognition-91bf2546b19e},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/6SBXMRRI/fine-tuning-layoutlm-v2-for-invoice-recognition-91bf2546b19e.html}
}

@misc{ApacheKafka,
  title = {Apache {{Kafka}}},
  journal = {Apache Kafka},
  abstract = {Apache Kafka: A Distributed Streaming Platform.},
  howpublished = {https://kafka.apache.org/documentation/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/RJWJFNSN/documentation.html}
}

@misc{ApacheKafkaKubernetes2020,
  title = {Apache {{Kafka}} on {{Kubernetes}} with {{Strimzi}} - {{Part}} 3: {{Monitoring}} Our {{Strimzi Kafka Cluster}} with {{Prometheus}} and {{Grafana}}},
  shorttitle = {Apache {{Kafka}} on {{Kubernetes}} with {{Strimzi}} - {{Part}} 3},
  year = {2020},
  month = oct,
  journal = {Sina Nourian},
  abstract = {Deploying Apache Kafka on Kubernetes with Strimzi; Producing and Consuming messages with Go and Scala; Monitoring with Prometheus and Grafana},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/UAX2JDNZ/kafka-kubernetes-strimzi-part-3-monitoring-strimzi-kafka-with-prometheus-grafana.html}
}

@misc{APIFlaskDocumentation,
  title = {{{API}} \textemdash{} {{Flask Documentation}} (2.1.x)},
  howpublished = {https://flask.palletsprojects.com/en/2.1.x/api/\#flask.Request.json}
}

@misc{APIReferenceOverview,
  title = {{{API Reference Overview}}},
  howpublished = {https://docs.clover.com/reference/api-reference-overview\#},
  file = {/home/dimdakis/Zotero/storage/LIG9DL9I/api-reference-overview.html}
}

@misc{ArtificialIntelligenceResearch,
  title = {Artificial {{Intelligence}} Research at {{Microsoft}} Aims to Enrich Our Experiences},
  journal = {Microsoft Research},
  abstract = {Microsoft AI Research is creating artificial intelligence machines that complement human reasoning to augment and enrich our experience and competencies.},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/VSWUL5WX/artificial-intelligence.html}
}

@misc{bachinaHowUseOwn2020,
  title = {How to {{Use Own Local Docker Images With Minikube}}},
  author = {Bachina, Bhargav},
  year = {2020},
  month = jan,
  journal = {Bachina Labs},
  abstract = {A step by step guide with an example project},
  langid = {english}
}

@misc{BERT,
  title = {{{BERT}}},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/model\_doc/bert},
  file = {/home/dimdakis/Zotero/storage/5UBZCPS2/bert.html}
}

@misc{BestCDCTools,
  title = {The 7 {{Best CDC Tools}} ({{Change Data Capture}}) - {{Learn}} | {{Hevo}}},
  howpublished = {https://hevodata.com/learn/7-best-cdc-tools/}
}

@misc{BigScienceResearchWorkshop,
  title = {{{BigScience Research Workshop}}},
  howpublished = {https://bigscience.huggingface.co/},
  file = {/home/dimdakis/Zotero/storage/ENHTNJZL/bigscience.huggingface.co.html}
}

@misc{BigscienceTr11176BmllogsHugging,
  title = {Bigscience/Tr11-{{176B-ml-logs}} {$\cdot$} {{Hugging Face}}},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/bigscience/tr11-176B-ml-logs},
  file = {/home/dimdakis/Zotero/storage/3EXBMSJY/tr11-176B-ml-logs.html}
}

@misc{brownleeEncoderDecoderRecurrentNeural2017,
  title = {Encoder-{{Decoder Recurrent Neural Network Models}} for {{Neural Machine Translation}}},
  author = {Brownlee, Jason},
  year = {2017},
  month = dec,
  journal = {Machine Learning Mastery},
  abstract = {The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases [\ldots ]},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/GQ9YK3AY/encoder-decoder-recurrent-neural-network-models-neural-machine-translation.html}
}

@misc{ClickUpOneApp,
  title = {{{ClickUp}}\texttrademark{} | {{One}} App to Replace Them All},
  abstract = {Our mission is to make the world more productive. To do this, we built one app to replace them all - Tasks, Docs, Goals, and Chat.},
  howpublished = {https://clickup.com},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/IX9VE5PD/clickup.com.html}
}

@misc{cloudfactoryDataAnnotationTools,
  title = {Data {{Annotation Tools}} for {{Machine Learning}}: {{An Evolving Guide}}},
  shorttitle = {Data {{Annotation Tools}} for {{Machine Learning}}},
  author = {CloudFactory},
  abstract = {Selecting the right tool to annotate your data can save you time, money, and frustration. This guide will help you understand how to choose the best data annotation tools for your machine learning project.},
  howpublished = {https://www.cloudfactory.com/data-annotation-tool-guide},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/8ZSS247W/data-annotation-tool-guide.html}
}

@misc{ComputerVisionCenter,
  title = {Computer {{Vision Center}} | {{The Computer Vision Centre}} ({{CVC}}) Is a Not for Profit Institute, Leader in Research and Development in the Field of Computer Vision},
  abstract = {The Computer Vision Centre (CVC) is a not for profit institute, leader in research and development in the field of computer vision},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/W6A38UW9/www.cvc.uab.es.html}
}

@misc{Concepts,
  title = {Concepts},
  journal = {Kubernetes},
  abstract = {Production-Grade Container Orchestration},
  howpublished = {https://kubernetes.io/docs/concepts/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/TGL364UJ/concepts.html}
}

@misc{ConnectorsDebeziumDocumentation,
  title = {Connectors :: {{Debezium Documentation}}},
  howpublished = {https://debezium.io/documentation/reference/stable/connectors/index.html},
  file = {/home/dimdakis/Zotero/storage/8VC4E2Y4/index.html}
}

@misc{CORDConsolidatedReceipt2022,
  title = {{{CORD}}: {{A Consolidated Receipt Dataset}} for {{Post-OCR Parsing}}},
  shorttitle = {{{CORD}}},
  year = {2022},
  month = mar,
  abstract = {CORD: A Consolidated Receipt Dataset for Post-OCR Parsing},
  copyright = {CC-BY-4.0},
  howpublished = {Clova AI Research}
}

@misc{cristinaTransformerAttentionMechanism2021,
  title = {The {{Transformer Attention Mechanism}}},
  author = {Cristina, Stefania},
  year = {2021},
  month = oct,
  journal = {Machine Learning Mastery},
  abstract = {Before the introduction of the Transformer model, the use of attention for neural machine translation was being implemented by RNN-based [\ldots ]},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/KSGA89ZB/the-transformer-attention-mechanism.html}
}

@misc{cristinaTransformerModel2021,
  title = {The {{Transformer Model}}},
  author = {Cristina, Stefania},
  year = {2021},
  month = nov,
  journal = {Machine Learning Mastery},
  abstract = {We have already familiarized ourselves with the concept of self-attention as implemented by the Transformer attention mechanism for neural machine [\ldots ]},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/SUYYIEZ5/the-transformer-model.html}
}

@misc{DD5D5V08elb,
  title = {{{DD5D5V08elb}}},
  howpublished = {https://link.medium.com/DD5D5V08elb}
}

@misc{DebeziumArchitectureDebezium,
  title = {Debezium {{Architecture}} :: {{Debezium Documentation}}},
  howpublished = {https://debezium.io/documentation/reference/architecture.html},
  file = {/home/dimdakis/Zotero/storage/VE2SE9E7/architecture.html}
}

@misc{debeziumcommunityDebezium,
  title = {Debezium},
  author = {{Debezium Community}},
  journal = {Debezium},
  abstract = {Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.},
  howpublished = {https://debezium.io/},
  file = {/home/dimdakis/Zotero/storage/GFF7BNDQ/debezium.io.html}
}

@misc{degioanniPhasesPrometheusAdoption2018,
  title = {3 Phases of {{Prometheus}} Adoption},
  author = {Degioanni, Loris},
  year = {2018},
  month = may,
  journal = {InfoWorld},
  abstract = {How to ensure visibility into your next-generation Kubernetes environment},
  howpublished = {https://www.infoworld.com/article/3275887/3-phases-of-prometheus-adoption.html},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/7BKALCZ8/3-phases-of-prometheus-adoption.html}
}

@misc{DeployingContainerizedAPI,
  title = {Deploying a {{Containerized API}} on {{Kubernetes}} | by Victor Steven | {{Level Up Coding}}},
  howpublished = {https://levelup.gitconnected.com/deploying-dockerized-golang-api-on-kubernetes-with-postgresql-mysql-d190e27ac09f},
  file = {/home/dimdakis/Zotero/storage/PRJC474R/Deploying a Containerized API on Kubernetes  by victor steven  Level Up Coding.html}
}

@misc{dhamiUnderstandingBERTWord2020,
  title = {Understanding {{BERT}} \textemdash{} {{Word Embeddings}}},
  author = {Dhami, Dharti},
  year = {2020},
  month = jul,
  journal = {Medium},
  abstract = {BERT Input},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/3GRNVALE/understanding-bert-word-embeddings-7dc4d2ea54ca.html}
}

@misc{DockercomposeCreateDb,
  title = {Docker-Compose and Create Db in {{Postgres}} on Init},
  journal = {Stack Overflow},
  howpublished = {https://stackoverflow.com/questions/59715622/docker-compose-and-create-db-in-postgres-on-init},
  file = {/home/dimdakis/Zotero/storage/FYAYL49B/docker-compose-and-create-db-in-postgres-on-init.html}
}

@misc{DockerimagesPostgres13,
  title = {Docker-Images/Postgres/13 at Main {$\cdot$} Debezium/Docker-Images},
  journal = {GitHub},
  abstract = {Docker images for Debezium. Please log issues in our JIRA at https://issues.redhat.com/projects/DBZ/summary - docker-images/postgres/13 at main {$\cdot$} debezium/docker-images},
  howpublished = {https://github.com/debezium/docker-images},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/FCR52T2E/13.html}
}

@misc{DockerimagesPostgresMain,
  title = {Docker-Images/Postgres/9.6 at Main {$\cdot$} Debezium/Docker-Images},
  journal = {GitHub},
  abstract = {Docker images for Debezium. Please log issues in our JIRA at https://issues.redhat.com/projects/DBZ/summary - docker-images/postgres/9.6 at main {$\cdot$} debezium/docker-images},
  howpublished = {https://github.com/debezium/docker-images},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/VS2MZTN9/9.html}
}

@misc{doshiTransformersExplainedVisually2021,
  title = {Transformers {{Explained Visually}} ({{Part}} 1): {{Overview}} of {{Functionality}}},
  shorttitle = {Transformers {{Explained Visually}} ({{Part}} 1)},
  author = {Doshi, Ketan},
  year = {2021},
  month = jun,
  journal = {Medium},
  abstract = {A Gentle Guide to Transformers for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.},
  howpublished = {https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/S75ZMAJQ/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452.html}
}

@misc{doshiTransformersExplainedVisually2021a,
  title = {Transformers {{Explained Visually}} ({{Part}} 3): {{Multi-head Attention}}, Deep Dive},
  shorttitle = {Transformers {{Explained Visually}} ({{Part}} 3)},
  author = {Doshi, Ketan},
  year = {2021},
  month = jun,
  journal = {Medium},
  abstract = {A Gentle Guide to the inner workings of Self-Attention, Encoder-Decoder Attention, Attention Score and Masking, in Plain English.},
  howpublished = {https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/SB5AYIX5/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853.html}
}

@misc{doshiTransformersExplainedVisually2021b,
  title = {Transformers {{Explained Visually}} \textemdash{} {{Not}} Just How, but {{Why}} They Work so Well},
  author = {Doshi, Ketan},
  year = {2021},
  month = jun,
  journal = {Medium},
  abstract = {A Gentle Guide to how the Attention Score calculations capture relationships between words in a sequence, in Plain English.},
  howpublished = {https://towardsdatascience.com/transformers-explained-visually-not-just-how-but-why-they-work-so-well-d840bd61a9d3},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/GZABTYYF/transformers-explained-visually-not-just-how-but-why-they-work-so-well-d840bd61a9d3.html}
}

@inproceedings{duttaAnnotationSoftwareImages2019,
  title = {The {{VIA Annotation Software}} for {{Images}}, {{Audio}} and {{Video}}},
  booktitle = {Proceedings of the 27th {{ACM International Conference}} on {{Multimedia}}},
  author = {Dutta, Abhishek and Zisserman, Andrew},
  year = {2019},
  month = oct,
  pages = {2276--2279},
  publisher = {{ACM}},
  address = {{Nice France}},
  doi = {10.1145/3343031.3350535},
  isbn = {978-1-4503-6889-6},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/68DG5Y4E/Dutta and Zisserman - 2019 - The VIA Annotation Software for Images, Audio and .pdf}
}

@misc{EasyUseText,
  title = {Easy to {{Use Text Annotation Tool}} | {{Upload}} Documents, Start Annotating, and Create Advanced {{NLP}} Model in a Few Hours.},
  abstract = {Easy to Use Text Annotation Tool | Upload documents in native PDF, CSV, Docx, html or ZIP format, start annotating, and create advanced NLP model in a few hours. Collaborate with other users to accelerate the document annotation process. Manage users, assign documents and track the annotation progress.        UBIAI high quality OCR annotation allow you to label native PDFs and images directly and auto annotate your dataset in multiple language annotation such as English, French and Arabic. UBIAI let you auto annotate your dataset using dictionaries (word, sentence and Regex inputs) and ML model.With UBIAI's built-in machine learning model, you can train and deploy your custom model without any code. Our NLP labeling tool supports Amazon Comprehend, JSON, Spacy, IOB, and CoreNLP formats},
  howpublished = {https://ubiai.tools/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/LKYLFYV5/ubiai.tools.html}
}

@misc{EasyUseTexta,
  title = {Easy to {{Use Text Annotation Tool}} | {{Upload}} Documents, Start Annotating, and Create Advanced {{NLP}} Model in a Few Hours.},
  abstract = {Easy to Use Text Annotation Tool | Upload documents in native PDF, CSV, Docx, html or ZIP format, start annotating, and create advanced NLP model in a few hours. Collaborate with other users to accelerate the document annotation process. Manage users, assign documents and track the annotation progress.        UBIAI high quality OCR annotation allow you to label native PDFs and images directly and auto annotate your dataset in multiple language annotation such as English, French and Arabic. UBIAI let you auto annotate your dataset using dictionaries (word, sentence and Regex inputs) and ML model.With UBIAI's built-in machine learning model, you can train and deploy your custom model without any code. Our NLP labeling tool supports Amazon Comprehend, JSON, Spacy, IOB, and CoreNLP formats},
  howpublished = {https://ubiai.tools/blog/article/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications},
  langid = {english}
}

@misc{EasyUseTextb,
  title = {Easy to {{Use Text Annotation Tool}} | {{Upload}} Documents, Start Annotating, and Create Advanced {{NLP}} Model in a Few Hours.},
  abstract = {Easy to Use Text Annotation Tool | Upload documents in native PDF, CSV, Docx, html or ZIP format, start annotating, and create advanced NLP model in a few hours. Collaborate with other users to accelerate the document annotation process. Manage users, assign documents and track the annotation progress.        UBIAI high quality OCR annotation allow you to label native PDFs and images directly and auto annotate your dataset in multiple language annotation such as English, French and Arabic. UBIAI let you auto annotate your dataset using dictionaries (word, sentence and Regex inputs) and ML model.With UBIAI's built-in machine learning model, you can train and deploy your custom model without any code. Our NLP labeling tool supports Amazon Comprehend, JSON, Spacy, IOB, and CoreNLP formats},
  howpublished = {https://ubiai.tools/blog/article/fine-tuning-transformer-model},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/4AZ686BU/fine-tuning-transformer-model.html}
}

@misc{EngineConfigurationSQLAlchemy,
  title = {Engine {{Configuration}} \textemdash{} {{SQLAlchemy}} 1.4 {{Documentation}}},
  howpublished = {https://docs.sqlalchemy.org/en/14/core/engines.html}
}

@misc{EventdrivenArchitectureMicroservices2020,
  title = {Event-Driven Architecture and Microservices Combination Concerns},
  year = {2020},
  month = jul,
  journal = {IBM Developer},
  abstract = {Complexities of combining EDA and microservices architecture styles to build scalable, distributed, highly available, fault-tolerant, and high-throughput systems.},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/EA34XYSL/eda-and-microservices-architecture-best-practices.html}
}

@misc{FacebookresearchDetectron22022,
  title = {Facebookresearch/Detectron2},
  year = {2022},
  month = apr,
  abstract = {Detectron2 is a platform for object detection, segmentation and other visual recognition tasks.},
  copyright = {Apache-2.0},
  howpublished = {Meta Research}
}

@misc{FasterRCNNExplained2020,
  title = {Faster {{R-CNN Explained}} for {{Object Detection Tasks}}},
  year = {2020},
  month = nov,
  journal = {Paperspace Blog},
  abstract = {We'll fully explain the Faster R-CNN model, and how it performs object detection using region-proposal networks.},
  howpublished = {https://blog.paperspace.com/faster-r-cnn-explained-object-detection/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/334WJY23/faster-r-cnn-explained-object-detection.html}
}

@misc{FeedforwardNeuralNetwork2022,
  title = {Feedforward {{Neural Network}}: {{Its Layers}}, {{Functions}}, and {{Importance}}},
  shorttitle = {Feedforward {{Neural Network}}},
  year = {2022},
  month = jan,
  journal = {Analytics Vidhya},
  abstract = {Feedforward Neural Networks, also known as Deep feedforward Networks or Multi-layer Perceptrons, are the focus of this article.},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/HHG34CSF/feedforward-neural-network-its-layers-functions-and-importance.html}
}

@misc{FUNSD,
  title = {{{FUNSD}}},
  howpublished = {https://guillaumejaume.github.io/FUNSD/},
  file = {/home/dimdakis/Zotero/storage/WWRRAKIR/FUNSD.html}
}

@misc{GentleIntroductionBatch,
  title = {A {{Gentle Introduction}} to {{Batch Normalization}} for {{Deep Neural Networks}}},
  howpublished = {https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/}
}

@misc{ghoshExtendingFlaskTutorial2021,
  title = {Extending the {{Flask}} Tutorial App into a Fully-Fledged, Highly Available, Cloud-Based Application},
  author = {Ghosh, Ren{\'e}},
  year = {2021},
  month = mar,
  journal = {Medium},
  abstract = {If you're starting out in Flask development, you'll likely have followed the online tutorial over at pallet projects\ldots},
  langid = {english}
}

@misc{GOCDCPostgres,
  title = {{{GOCDC}} and {{Postgres}}},
  howpublished = {https://dev.to/thiagosilvaf/gocdc-and-postgres-1m4m}
}

@misc{GorillaMux2021,
  title = {Gorilla/Mux},
  year = {2021},
  month = oct,
  abstract = {A powerful HTTP router and URL matcher for building Go web servers with 🦍},
  copyright = {BSD-3-Clause},
  howpublished = {Gorilla Web Toolkit},
  keywords = {go,gorilla,http,middleware,mux,router}
}

@misc{GPT3PowersNext2021,
  title = {{{GPT-3 Powers}} the {{Next Generation}} of {{Apps}}},
  year = {2021},
  month = mar,
  journal = {OpenAI},
  abstract = {Over 300 applications are delivering GPT-3\textendash powered search, conversation, text completion, and other advanced AI features through our API.},
  howpublished = {https://openai.com/blog/gpt-3-apps/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/MB95T8TI/gpt-3-apps.html}
}

@misc{GrafanaOpenObservability,
  title = {Grafana: {{The}} Open Observability Platform},
  shorttitle = {Grafana},
  journal = {Grafana Labs},
  abstract = {Grafana is the open source analytics \& monitoring solution for every database.},
  howpublished = {https://grafana.com/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/GTHDN47S/grafana.com.html}
}

@misc{guptaDeepLearningFeedforward2018,
  title = {Deep {{Learning}}: {{Feedforward Neural Network}}},
  shorttitle = {Deep {{Learning}}},
  author = {Gupta, Tushar},
  year = {2018},
  month = dec,
  journal = {Medium},
  abstract = {Coming to the third part of the series. In this article I would be explain the concept of Deep Feedforward Networks.},
  howpublished = {https://towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/9E8W4RAA/deep-learning-feedforward-neural-network-26a6705dbdc7.html}
}

@misc{Helm,
  title = {Helm},
  abstract = {Helm - The Kubernetes Package Manager.},
  howpublished = {https://helm.sh/},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/LQN9LERF/helm.sh.html}
}

@misc{HowGiantCompanies,
  title = {How 8 {{Giant Companies Use Kubernetes}} \& 60 {{Others That Use It}}},
  abstract = {This guide gives an in-depth look at how 8 well-known companies use Kubernetes \& lists 60 others that use it.},
  howpublished = {https://www.containiq.com/post/companies-using-kubernetes},
  file = {/home/dimdakis/Zotero/storage/F2A44NEI/companies-using-kubernetes.html}
}

@misc{HowIntegrateKafka,
  title = {How to Integrate {{Kafka}} with {{Istio}} on {{OpenShift}}},
  howpublished = {https://labs.consol.de/development/2021/02/02/istio\_and\_kafka\_on\_openshift.html}
}

@misc{HowPlotTrain,
  title = {How to Plot Train and Validation Accuracy Graph?},
  howpublished = {https://discuss.pytorch.org/t/how-to-plot-train-and-validation-accuracy-graph/105524}
}

@misc{HowUseChange,
  title = {How to Use {{Change Data Capture}} ({{CDC}}) with {{Postgres}}},
  howpublished = {https://dev.to/thiagosilvaf/how-to-use-change-database-capture-cdc-in-postgres-37b8}
}

@misc{HuggingFaceAI,
  title = {Hugging {{Face}} \textendash{} {{The AI}} Community Building the Future.},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/},
  file = {/home/dimdakis/Zotero/storage/RG3K8PCF/huggingface.co.html}
}

@misc{HuggingFaceAIa,
  title = {Hugging {{Face}} \textendash{} {{The AI}} Community Building the Future.},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/datasets},
  file = {/home/dimdakis/Zotero/storage/TZ5SNMYA/datasets.html}
}

@misc{HuggingFaceTransformers,
  title = {Hugging {{Face Transformers Package}} - {{What Is It}} and {{How To Use It}}},
  journal = {KDnuggets},
  abstract = {The rapid development of Transformers have brought a new wave of powerful tools to natural language processing. These models are large and very expensive to train, so pre-trained versions are shared and leveraged by researchers and practitioners. Hugging Face offers a wide variety of pre-trained transformers as open-source libraries, and\ldots},
  chapter = {2021 Feb Tutorials, Overviews},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/WR3ETSKR/hugging-face-transformer-basics.html}
}

@misc{InstallationGuideNGINX,
  title = {Installation {{Guide}} - {{NGINX Ingress Controller}}},
  howpublished = {https://kubernetes.github.io/ingress-nginx/deploy/}
}

@misc{IntelligentDocumentProcessing,
  title = {Intelligent Document Processing with {{AI}}},
  howpublished = {https://nanonets.com/blog/receipt-ocr/\%23receipt-digitization-using-tesseract}
}

@misc{issaevBeginnerGuideLoading2020,
  title = {Beginner's {{Guide}} to {{Loading Image Data}} with {{PyTorch}}},
  author = {Issaev, Sergei},
  year = {2020},
  month = dec,
  journal = {Medium},
  abstract = {As data scientists, we deal with incoming data in a wide variety of formats. When it comes to loading image data with PyTorch, the\ldots},
  howpublished = {https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/R3BZHR8S/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec.html}
}

@misc{KafkaConnectConfluent,
  title = {Kafka {{Connect}} | {{Confluent Documentation}}},
  howpublished = {https://docs.confluent.io/platform/current/connect/index.html},
  file = {/home/dimdakis/Zotero/storage/S7T2ZSPI/index.html}
}

@misc{kamaniImplementingKafkaProducer,
  title = {Implementing a {{Kafka Producer}} and {{Consumer In Golang}} ({{With Full Examples}}) {{For Production}}},
  author = {Kamani, Soham},
  howpublished = {https://www.sohamkamani.com/golang/working-with-kafka/}
}

@misc{khannaWordPieceSubwordbasedTokenization2021,
  title = {{{WordPiece}}: {{Subword-based}} Tokenization Algorithm},
  shorttitle = {{{WordPiece}}},
  author = {Khanna, Chetna},
  year = {2021},
  month = aug,
  journal = {Medium},
  abstract = {Understand subword-based tokenization algorithm used by state-of-the-art NLP models{$\mkern1mu$}\textemdash{$\mkern1mu$}WordPiece},
  howpublished = {https://towardsdatascience.com/wordpiece-subword-based-tokenization-algorithm-1fbd14394ed7},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/BKBEV3K5/wordpiece-subword-based-tokenization-algorithm-1fbd14394ed7.html}
}

@misc{KubernetesAdoptionTrends,
  title = {Kubernetes {{Adoption Trends Report}}},
  howpublished = {https://www.cockroachlabs.com/guides/kubernetes-trends/},
  file = {/home/dimdakis/Zotero/storage/5X8X75AZ/kubernetes-trends.html}
}

@misc{KubernetesOperatorStateful2021,
  title = {Kubernetes {{Operator}} | {{Stateful Kubernetes Application}}},
  year = {2021},
  month = may,
  journal = {Cloud Training Program},
  abstract = {Kubernetes Operator are a replacement of the engineers who are responsible to operate the system. It has knowledge about the current and the desired state.},
  howpublished = {https://k21academy.com/docker-kubernetes/kubernetes-operator/},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/ZRC7M3VZ/kubernetes-operator.html}
}

@misc{KubernetesSecurityBest,
  title = {Kubernetes {{Security Best Practices}}: 10 {{Steps}} to {{Securing K8s}}},
  howpublished = {https://www.aquasec.com/cloud-native-academy/kubernetes-in-production/kubernetes-security-best-practices-10-steps-to-securing-k8s/}
}

@misc{kudariSQLAlchemyPythonTutorial2020,
  title = {{{SQLAlchemy}} \textemdash{} {{Python Tutorial}}},
  author = {Kudari, Vinay},
  year = {2020},
  month = sep,
  journal = {Medium},
  abstract = {We often encounter data as Relational Databases. To work with them we generally would need to write raw SQL queries, pass them to the\ldots},
  howpublished = {https://towardsdatascience.com/sqlalchemy-python-tutorial-79a577141a91},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/AG7KGNPD/sqlalchemy-python-tutorial-79a577141a91.html}
}

@misc{kutayChangeDataCapture2021,
  title = {Change {{Data Capture}} ({{CDC}}): {{What}} It Is and {{How}} It {{Works}}},
  shorttitle = {Change {{Data Capture}} ({{CDC}})},
  author = {Kutay, John},
  year = {2021},
  month = may,
  journal = {Striim},
  abstract = {Change Data Capture is ideal for real time data movement. Learn how it works, the best use cases for CDC, and the role it plays in streaming ETL.},
  chapter = {CDC},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/7MYRK8MN/change-data-capture-cdc-what-it-is-and-how-it-works.html}
}

@misc{LabelStudioOpen,
  title = {Label {{Studio}} \textendash{} {{Open Source Data Labeling}}},
  abstract = {Most flexible data labeling tool that supports all your data types. Prepare training data for computer vision, natural language processing, speech, voice, and video models.},
  howpublished = {https://labelstud.io/},
  file = {/home/dimdakis/Zotero/storage/VJIMR2Y7/labelstud.io.html}
}

@misc{LAMBERT2022,
  title = {{{LAMBERT}}},
  year = {2022},
  month = apr,
  abstract = {Publicly released code for the LAMBERT model},
  howpublished = {Applica}
}

@misc{LayoutLMExplained2022,
  title = {{{LayoutLM Explained}}},
  year = {2022},
  month = mar,
  journal = {AI \& Machine Learning Blog},
  abstract = {LayoutLM is a deep learning model used to perform document processing. In this article we share a LayoutLM tutorial, a deeper dive in architecture, and provide code samples for HuggingFace LayoutLM},
  howpublished = {https://nanonets.com/blog/layoutlm-explained/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/46ISG8W8/layoutlm-explained.html}
}

@misc{LayoutLMV2,
  title = {{{LayoutLMV2}}},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/model\_doc/layoutlmv2},
  file = {/home/dimdakis/Zotero/storage/F969IVJA/layoutlmv2.html}
}

@misc{LessonsLearnedRunning,
  title = {Lessons {{Learned}} from {{Running Debezium}} with {{PostgreSQL}} on {{Amazon RDS}}},
  howpublished = {https://debezium.io/blog/2020/02/25/lessons-learned-running-debezium-with-postgresql-on-rds/}
}

@misc{LightTagTextAnnotation,
  title = {{{LightTag}} - {{The Text Annotation Tool For Teams}}},
  howpublished = {https://www.lighttag.io/},
  file = {/home/dimdakis/Zotero/storage/L6CDSPXX/www.lighttag.io.html}
}

@misc{LogicalDecodingOutput,
  title = {Logical {{Decoding Output Plug-in Installation}} for {{PostgreSQL}} :: {{Debezium Documentation}}},
  howpublished = {https://debezium.io/documentation/reference/postgres-plugins.html},
  file = {/home/dimdakis/Zotero/storage/AP3XHUXI/postgres-plugins.html}
}

@misc{MethodStrucTexTTask,
  title = {Method: {{StrucTexT}} - {{Task}} 3 - {{Key Information Extraction}} - {{ICDAR}} 2019 {{Robust Reading Challenge}} on {{Scanned Receipts OCR}} and {{Information Extraction}} - {{Robust Reading Competition}}},
  howpublished = {https://rrc.cvc.uab.es/?ch=13\&com=evaluation\&view=method\_info\&task=3\&m=90335},
  file = {/home/dimdakis/Zotero/storage/TFEHEXIZ/rrc.cvc.uab.es.html}
}

@misc{MinikubeStart,
  title = {Minikube Start},
  journal = {minikube},
  abstract = {minikube is local Kubernetes},
  howpublished = {https://minikube.sigs.k8s.io/docs/start/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/G46IY2P3/start.html}
}

@misc{ModelsHuggingFace,
  title = {Models - {{Hugging Face}}},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/models},
  file = {/home/dimdakis/Zotero/storage/383T6HMK/models.html}
}

@misc{munozAttentionAllYou2021,
  title = {Attention Is All You Need: {{Discovering}} the {{Transformer}} Paper},
  shorttitle = {Attention Is All You Need},
  author = {Mu{\~n}oz, Eduardo},
  year = {2021},
  month = feb,
  journal = {Medium},
  abstract = {Detailed implementation of a Transformer model in Tensorflow},
  howpublished = {https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/W7IF9JUN/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634.html}
}

@misc{naincyjainEffectBatchSize,
  title = {Effect of {{Batch Size}} on {{Training Process}} and Results by {{Gradient Accumulation}}},
  author = {Naincyjain},
  howpublished = {https://medium.com/analytics-vidhya/effect-of-batch-size-on-training-process-and-results-by-gradient-accumulation-e7252ee2cb3f}
}

@misc{nathGracefulShutdownGolang2019,
  title = {Graceful Shutdown of {{Golang}} Servers Using {{Context}} and {{OS}} Signals},
  author = {Nath, Pinku Deb},
  year = {2019},
  month = may,
  journal = {Medium},
  abstract = {Whenever a server needs to shut down for various reasons, the common one being OS interrupts, we would want our servers to shut down\ldots},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/6WUCTKFQ/graceful-shutdown-of-golang-servers-using-context-and-os-signals-cc1fa2c55e97.html}
}

@misc{OpenAIAPI,
  title = {{{OpenAI API}}},
  abstract = {An API for accessing new AI models developed by OpenAI},
  howpublished = {https://beta.openai.com},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/9BIUKY5J/examples.html}
}

@misc{OperatorPattern,
  title = {Operator Pattern},
  journal = {Kubernetes},
  abstract = {Operators are software extensions to Kubernetes that make use of custom resources to manage applications and their components. Operators follow Kubernetes principles, notably the control loop. Motivation The Operator pattern aims to capture the key aim of a human operator who is managing a service or set of services. Human operators who look after specific applications and services have deep knowledge of how the system ought to behave, how to deploy it, and how to react if there are problems.},
  chapter = {docs},
  howpublished = {https://kubernetes.io/docs/concepts/extend-kubernetes/operator/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/2B974M26/operator.html}
}

@misc{OverviewICDAR2019,
  title = {Overview - {{ICDAR}} 2019 {{Robust Reading Challenge}} on {{Scanned Receipts OCR}} and {{Information Extraction}} - {{Robust Reading Competition}}},
  howpublished = {https://rrc.cvc.uab.es/?ch=13},
  file = {/home/dimdakis/Zotero/storage/PTVVKC7T/rrc.cvc.uab.es.html}
}

@misc{PartHandlingMigrations,
  title = {Part 5: {{Handling Migrations With Gorm}} in {{Go}} | {{Code}} Sahara},
  howpublished = {https://codesahara.com/blog/making-migrations-with-gorm-in-go/},
  keywords = {gorm migrations},
  file = {/home/dimdakis/Zotero/storage/YEJ2YA5T/making-migrations-with-gorm-in-go.html}
}

@misc{PGOPostgresOperator,
  title = {{{PGO}}, the {{Postgres Operator}} from {{Crunchy Data}}},
  howpublished = {https://access.crunchydata.com/documentation/postgres-operator/5.0.5/tutorial/connect-cluster/},
  file = {/home/dimdakis/Zotero/storage/KYAPNFLH/connect-cluster.html}
}

@misc{PodKubernetesEngine,
  title = {Pod ~|~ {{Kubernetes Engine Documentation}} ~|~ {{Google Cloud}}},
  howpublished = {https://cloud.google.com/kubernetes-engine/docs/concepts/pod},
  file = {/home/dimdakis/Zotero/storage/MKUX9LLS/pod.html}
}

@misc{PostgreSQLLinuxDownloads,
  title = {{{PostgreSQL}}: {{Linux}} Downloads ({{Ubuntu}})},
  howpublished = {https://www.postgresql.org/download/linux/ubuntu/},
  file = {/home/dimdakis/Zotero/storage/UZ6R4S43/ubuntu.html}
}

@misc{ProductionGradeContainerOrchestration,
  title = {Production-{{Grade Container Orchestration}}},
  journal = {Kubernetes},
  abstract = {Production-Grade Container Orchestration},
  howpublished = {https://kubernetes.io/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/HVIGLI4Z/kubernetes.io.html}
}

@misc{prometheusPrometheusMonitoringSystema,
  title = {Prometheus - {{Monitoring}} System \& Time Series Database},
  author = {Prometheus},
  abstract = {An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.},
  howpublished = {https://prometheus.io/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/ADG34MBU/prometheus.io.html}
}

@misc{pythonFlaskExampleSetting,
  title = {Flask by {{Example}} \textendash{} {{Setting}} up {{Postgres}}, {{SQLAlchemy}}, and {{Alembic}} \textendash{} {{Real Python}}},
  author = {Python, Real},
  abstract = {This tutorial shows you how to process text and then setup a task queue with Flask. In part two, we'll set up our PostgreSQL database along with SQLAlchemy and Alembic to handle migrations.},
  howpublished = {https://realpython.com/flask-by-example-part-2-postgres-sqlalchemy-and-alembic/},
  langid = {english}
}

@misc{pythonHowBuildCommand,
  title = {How to {{Build Command Line Interfaces}} in {{Python With}} Argparse \textendash{} {{Real Python}}},
  author = {Python, Real},
  abstract = {In this step-by-step Python tutorial, you'll learn how to take your command line Python scripts to the next level by adding a convenient command line interface that you can write with argparse.},
  howpublished = {https://realpython.com/command-line-interfaces-python-argparse/},
  langid = {english}
}

@misc{PythonHTTPRequest2019,
  title = {Python {{HTTP Request Tutorial}}: {{Get}} \& {{Post HTTP}} \& {{JSON Requests}}},
  shorttitle = {Python {{HTTP Request Tutorial}}},
  year = {2019},
  month = sep,
  journal = {DataCamp Community},
  abstract = {Learn about Python Request library and how to make a request. Follow examples to Get \& Post HTTP \& JSON requests today!},
  howpublished = {https://www.datacamp.com/community/tutorials/making-http-requests-in-python},
  file = {/home/dimdakis/Zotero/storage/S6GWPILF/making-http-requests-in-python.html}
}

@misc{ReleasesStrimziStrimzikafkaoperator,
  title = {Releases {$\cdot$} Strimzi/Strimzi-Kafka-Operator},
  journal = {GitHub},
  abstract = {Apache Kafka running on Kubernetes. Contribute to strimzi/strimzi-kafka-operator development by creating an account on GitHub.},
  howpublished = {https://github.com/strimzi/strimzi-kafka-operator/releases},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/GXFZJ9FN/0.26.html}
}

@misc{ResultsICDAR2019a,
  title = {Results - {{ICDAR}} 2019 {{Robust Reading Challenge}} on {{Scanned Receipts OCR}} and {{Information Extraction}} - {{Robust Reading Competition}}},
  howpublished = {https://rrc.cvc.uab.es/?ch=13\&com=evaluation\&task=3},
  file = {/home/dimdakis/Zotero/storage/A9REYKPX/rrc.cvc.uab.es.html}
}

@misc{RoBERTa,
  title = {{{RoBERTa}}},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/model\_doc/roberta},
  file = {/home/dimdakis/Zotero/storage/DRSGK8HP/roberta.html}
}

@misc{RoleThatSMEs,
  title = {The {{Role That SMEs Will Play}} in {{Rebuilding}} the {{Irish Economy}} ({{Free Downloadable Executive Summary}})},
  abstract = {The Role That SMEs Will Play in Rebuilding the Irish Economy.},
  howpublished = {https://aibf.ie/times/the-role-that-smes-will-play-in-rebuilding-the-irish-economy-free-downloadable-executive-summary/}
}

@misc{rusevImboxPythonIMAP,
  title = {Imbox: {{Python IMAP}} for {{Human}} Beings},
  shorttitle = {Imbox},
  author = {Rusev, Martin},
  copyright = {MIT},
  keywords = {email;,IMAP;,parsing emails},
  file = {/home/dimdakis/Zotero/storage/T43ZM4WU/imbox.html}
}

@misc{saysKubernetesDesiredState2019,
  title = {Kubernetes - {{Desired State}} and {{Control Loops}}},
  author = {{says}, Sub},
  year = {2019},
  month = sep,
  journal = {The IT Hollow},
  abstract = {If you've just gotten started with Kubernetes, you might be curious to know how the desired state is achieved? Think\ldots},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/BY28S9ZV/kubernetes-desired-state-and-control-loops.html}
}

@misc{Secrets,
  title = {Secrets},
  journal = {Kubernetes},
  abstract = {A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key. Such information might otherwise be put in a Pod specification or in a container image. Using a Secret means that you don't need to include confidential data in your application code. Because Secrets can be created independently of the Pods that use them, there is less risk of the Secret (and its data) being exposed during the workflow of creating, viewing, and editing Pods.},
  chapter = {docs},
  howpublished = {https://kubernetes.io/docs/concepts/configuration/secret/},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/NGK4PZM8/secret.html}
}

@misc{sotiriouFaultToleranceKubernetes2020,
  title = {Fault {{Tolerance}} in {{Kubernetes Clusters}}},
  author = {Sotiriou, Christos},
  year = {2020},
  month = apr,
  journal = {The Startup},
  abstract = {What is it, why you should care, and how to apply it using Quarkus},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/M8L585U5/fault-tolerance-in-kubernetes-clusters-f5d707bc8b5c.html}
}

@misc{SQLAlchemyDatabaseToolkit,
  title = {{{SQLAlchemy}} - {{The Database Toolkit}} for {{Python}}},
  howpublished = {https://www.sqlalchemy.org/},
  file = {/home/dimdakis/Zotero/storage/LKSWKVUF/www.sqlalchemy.org.html}
}

@misc{SquareSolutionsTools,
  title = {{Square: Solutions \& Tools to Grow Your Business}},
  shorttitle = {{Square}},
  journal = {Square},
  abstract = {Square helps millions of sellers run their business \textendash{} from secure credit card processing, point of sale solutions to setting up a free online store. Get paid faster with Square and sign up today!},
  howpublished = {https://squareup.com/ie/en},
  langid = {en-IE},
  file = {/home/dimdakis/Zotero/storage/YH6H72QL/en.html}
}

@misc{StrimziDocumentation16,
  title = {Strimzi {{Documentation}} (0.16.2)},
  howpublished = {https://strimzi.io/docs/0.16.2/},
  file = {/home/dimdakis/Zotero/storage/2I5KXDBZ/0.16.2.html}
}

@misc{StrimziQuickStart,
  title = {Strimzi {{Quick Start}} Guide (0.26.0)},
  howpublished = {https://strimzi.io/docs/operators/latest/quickstart.html},
  file = {/home/dimdakis/Zotero/storage/TB2Y3BYQ/quickstart.html}
}

@misc{SummaryTokenizers,
  title = {Summary of the Tokenizers},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/tokenizer\_summary},
  file = {/home/dimdakis/Zotero/storage/AJXUULVC/tokenizer_summary.html}
}

@misc{syalHuggingFaceStep2020,
  title = {Hugging {{Face}}: {{A Step Towards Democratizing NLP}}},
  shorttitle = {Hugging {{Face}}},
  author = {Syal, Anuj},
  year = {2020},
  month = dec,
  journal = {Medium},
  abstract = {It's not an emoji, it's NLP for everyone},
  howpublished = {https://towardsdatascience.com/hugging-face-a-step-towards-democratizing-nlp-2c79f258c951},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/4T4QQWG6/hugging-face-a-step-towards-democratizing-nlp-2c79f258c951.html}
}

@misc{TEMxXnwlvmb,
  title = {{{tEMxXnwlvmb}}},
  howpublished = {https://link.medium.com/tEMxXnwlvmb}
}

@misc{TipsTricksRunning,
  title = {Tips \& {{Tricks}} for Running {{Strimzi}} with Kubectl},
  howpublished = {https://strimzi.io/blog/2020/07/22/tips-and-tricks-for-running-strimzi-with-kubectl/},
  file = {/home/dimdakis/Zotero/storage/I9CTCBJW/tips-and-tricks-for-running-strimzi-with-kubectl.html}
}

@misc{TokenClassification,
  title = {Token Classification},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/main/en/tasks/token\_classification},
  file = {/home/dimdakis/Zotero/storage/XMZ6VTA3/token_classification.html}
}

@misc{Transformers,
  title = {Transformers},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/docs/transformers/index},
  file = {/home/dimdakis/Zotero/storage/BCF2836N/index.html}
}

@misc{UnderstandingBackpropagationNeural,
  title = {Understanding {{Backpropagation}} in a {{Neural Network}} - 1},
  howpublished = {https://www.linkedin.com/pulse/understanding-backpropagation-neural-network-1-srikanth-machiraju/}
}

@misc{UsingHelm,
  title = {Using {{Helm}}},
  howpublished = {https://helm.sh/docs/intro/using\_helm/}
}

@misc{UsingSQLAlchemyFlask2017,
  title = {Using {{SQLAlchemy}} with {{Flask}} to {{Connect}} to {{PostgreSQL}}},
  year = {2017},
  month = aug,
  journal = {vsupalov.com},
  abstract = {Connecting to PostgreSQL from a Flask app, and defining models.},
  howpublished = {https://vsupalov.com/flask-sqlalchemy-postgres/},
  langid = {english}
}

@misc{UsingSQLAlchemyFlask2020,
  title = {Using {{SQLAlchemy}} with {{Flask}} and {{PostgreSQL}}},
  year = {2020},
  month = jan,
  journal = {Stack Abuse},
  abstract = {Nowadays, Object-Relational Mappers like SQLAlchemy are used as a bridge between applications and SQL databases and make it easy to work with them programmatically.},
  howpublished = {https://stackabuse.com/using-sqlalchemy-with-flask-and-postgresql/},
  langid = {english}
}

@misc{UsingStrimzi,
  title = {Using {{Strimzi}}},
  howpublished = {https://strimzi.io/docs/operators/latest/full/using.html}
}

@article{vaswaniAttentionAllYou,
  title = {Attention Is {{All}} You {{Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  pages = {11},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/NI87Q83X/Vaswani et al. - Attention is All you Need.pdf}
}

@misc{velichkoHowGraspContainers,
  title = {How to {{Grasp Containers}} - {{Efficient Learning Path}} - {{Ivan Velichko}}},
  author = {Velichko, Ivan},
  howpublished = {https://iximiuz.com/en/posts/container-learning-path/}
}

@misc{vijayraniaDifferentNormalizationLayers2021,
  title = {Different {{Normalization Layers}} in {{Deep Learning}}},
  author = {Vijayrania, Nilesh},
  year = {2021},
  month = mar,
  journal = {Medium},
  abstract = {Presently Deep Learning has been revolutionizing many subfields such as natural language processing, computer vision, robotics, etc. Deep\ldots},
  howpublished = {https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/CHIDP3NH/different-normalization-layers-in-deep-learning-1a7214ff71d6.html}
}

@misc{wadaLabelmeImagePolygonal2022,
  title = {Labelme: {{Image Polygonal Annotation}} with {{Python}}},
  shorttitle = {Labelme},
  author = {Wada, Kentaro},
  year = {2022},
  month = apr,
  doi = {10.5281/zenodo.5711226},
  abstract = {Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).}
}

@misc{WhatEventdrivenArchitecture,
  title = {What Is Event-Driven Architecture?},
  howpublished = {https://www.redhat.com/en/topics/integration/what-is-event-driven-architecture},
  file = {/home/dimdakis/Zotero/storage/FR9MBNIR/what-is-event-driven-architecture.html}
}

@misc{WhatHelmChart2019,
  title = {What {{Is A Helm Chart}}? \textendash{} {{A Beginner}}'s {{Guide}}},
  shorttitle = {What {{Is A Helm Chart}}?},
  year = {2019},
  month = aug,
  journal = {Coveros},
  abstract = {Helm is a Kubernetes package and operations manager. The name ``kubernetes'' is derived from the Greek word for ``pilot'' or ``helmsman'', making Helm its steering wheel. Using a packaging manager, Charts, Helm allows us to package Kubernetes releases into a convenient zip (.tgz) file. A Helm chart can contain any number of Kubernetes objects, all [\ldots ]},
  langid = {american},
  file = {/home/dimdakis/Zotero/storage/QIRGPMNE/what-is-a-helm-chart-a-beginners-guide.html}
}

@misc{WhatKubernetesOperator,
  title = {What Is a {{Kubernetes}} Operator?},
  abstract = {A Kubernetes operator is a method of packaging, deploying, and managing an application by extending the functionality of the Kubernetes API.},
  howpublished = {https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/IY5I3P4X/what-is-a-kubernetes-operator.html}
}

@misc{WhatMakefileHow,
  title = {What Is a {{Makefile}} and How Does It Work?},
  howpublished = {https://opensource.com/article/18/8/what-how-makefile}
}

@misc{WhatTokenizationTokenization2020,
  title = {What Is {{Tokenization}} | {{Tokenization In NLP}}},
  year = {2020},
  month = may,
  journal = {Analytics Vidhya},
  abstract = {Tokenization is an NLP concept you should know before entering the field. Learn what is tokenization and working of tokenization in NLP using python.},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/W6BWIEGT/what-is-tokenization-nlp.html}
}

@misc{WhatTransferLearning2021,
  title = {What Is Transfer Learning and Why Is It Needed? - {{Beginners}}},
  shorttitle = {What Is Transfer Learning and Why Is It Needed?},
  year = {2021},
  month = mar,
  journal = {Hugging Face Forums},
  abstract = {I am using Hugging Face Models for NLP tasks.  I see a lot of online examples like below which freezes the bottom layers and only train only few top layers. Basic idea is to use transfer learning, without having to train model from scratch. Which makes sense to me.  for layer in model.layers[:-2]:     layer.trainable = False  However i find that accuracy of my model improves significantly when train it from scratch, Are there any downsides to train transformer model from scratch? What is the rig...},
  howpublished = {https://discuss.huggingface.co/t/what-is-transfer-learning-and-why-is-it-needed/4431},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/4JW5Z2JC/4431.html}
}

@misc{WhatZookeeperWhy,
  title = {What Is {{Zookeeper}} and Why Is It Needed for {{Apache Kafka}}? - {{CloudKarafka}}, {{Apache Kafka Message}} Streaming as a {{Service}}},
  shorttitle = {What Is {{Zookeeper}} and Why Is It Needed for {{Apache Kafka}}?},
  abstract = {Are you using Apache Kafka to build message streaming services? Then you might have run into the expression Zookeeper. To us at CloudKarafka, as a Apache Kafka hosting service, it's important that our users understand what Zookeeper is and how it integrates with Kafka.},
  howpublished = {https://www.cloudkarafka.com/blog/cloudkarafka-what-is-zookeeper.html},
  langid = {english},
  file = {/home/dimdakis/Zotero/storage/2BX7YJYB/cloudkarafka-what-is-zookeeper.html}
}

@misc{WhoUsingDebezium,
  title = {Who's {{Using Debezium}}?},
  journal = {Debezium},
  abstract = {Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.},
  howpublished = {https://debezium.io/community/users/},
  file = {/home/dimdakis/Zotero/storage/HIR6YUTZ/users.html}
}

@article{xuLayoutLMv2MultimodalPretraining2022,
  title = {{{LayoutLMv2}}: {{Multi-modal Pre-training}} for {{Visually-Rich Document Understanding}}},
  shorttitle = {{{LayoutLMv2}}},
  author = {Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and Zhang, Min and Zhou, Lidong},
  year = {2022},
  month = jan,
  journal = {arXiv:2012.14740 [cs]},
  eprint = {2012.14740},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Pre-training of text and layout has proved effective in a variety of visually-rich document understanding tasks due to its effective model architecture and the advantage of large-scale unlabeled scanned/digital-born documents. We propose LayoutLMv2 architecture with new pre-training tasks to model the interaction among text, layout, and image in a single multi-modal framework. Specifically, with a two-stream multi-modal Transformer encoder, LayoutLMv2 uses not only the existing masked visual-language modeling task but also the new text-image alignment and text-image matching tasks, which make it better capture the cross-modality interaction in the pre-training stage. Meanwhile, it also integrates a spatial-aware self-attention mechanism into the Transformer architecture so that the model can fully understand the relative positional relationship among different text blocks. Experiment results show that LayoutLMv2 outperforms LayoutLM by a large margin and achieves new state-ofthe-art results on a wide variety of downstream visually-rich document understanding tasks, including FUNSD (0.7895 \textrightarrow{} 0.8420), CORD (0.9493 \textrightarrow{} 0.9601), SROIE (0.9524 \textrightarrow{} 0.9781), Kleister-NDA (0.8340 \textrightarrow{} 0.8520), RVL-CDIP (0.9443 \textrightarrow{} 0.9564), and DocVQA (0.7295 \textrightarrow{} 0.8672). We made our model and code publicly available at https://aka.ms /layoutlmv2.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dimdakis/Zotero/storage/UPMSVEYX/Xu et al. - 2022 - LayoutLMv2 Multi-modal Pre-training for Visually-.pdf}
}


